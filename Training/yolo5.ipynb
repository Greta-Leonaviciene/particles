{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook is responsible for YOLOv5 model training using custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob as glob\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import requests\n",
    "import random\n",
    "import numpy as np\n",
    "import wandb\n",
    "import torch\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = True\n",
    "EPOCHS = 200\n",
    "\n",
    "# Remove albumentations that yolo applies automatically if installed\n",
    "! pip3 uninstall albumentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize a few ground truth images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of class names\n",
    "class_names = [\"Defective\", \"Speckled\", \"Beaded\",\"Clear\", \"Unknown\"]\n",
    "\n",
    "# Define the colors for each class\n",
    "colors = [\n",
    "    (255, 56, 56),   # Red (Class 0)\n",
    "    (255, 157, 151), # Light Red (Class 1)\n",
    "    (255, 112, 31),  # Orange (Class 2)\n",
    "    (255, 178, 29),  # Yellow (Class 3)\n",
    "    (50, 205, 100),   # Green (Class 4)\n",
    "]\n",
    "\n",
    "# Define paths to your dataset\n",
    "train_images_path = 'data/train/images'\n",
    "train_labels_path = 'data/train/labels'\n",
    "valid_images_path = 'data/valid/images'\n",
    "valid_labels_path = 'data/valid/labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to plot one bounding box\n",
    "def plot_one_box(x, img, color=None, label=None, line_thickness=2):\n",
    "    # Coordinates of the bounding box\n",
    "    x1, y1, x2, y2 = [int(i) for i in x]\n",
    "    # Draw rectangle\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), color, thickness=line_thickness)\n",
    "    # Draw label if provided\n",
    "    if label:\n",
    "        font_scale = 0.7\n",
    "        font_thickness = 1\n",
    "        t_size = cv2.getTextSize(label, 0, font_scale, font_thickness)[0]\n",
    "        cv2.putText(img, label, (x1, y1 - 2), 0, font_scale, color, font_thickness, lineType=cv2.LINE_AA)\n",
    "\n",
    "# Function to visualize the images with ground truth bounding boxes\n",
    "def visualize_ground_truth(image_dir, label_dir, class_names, num_images=16):\n",
    "    images = os.listdir(image_dir)\n",
    "\n",
    "    # Create a 4x4 subplot\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "    axes = axes.flatten()  # Flatten the 4x4 array to iterate easily\n",
    "\n",
    "    for idx, image_file in enumerate(images[:num_images]):\n",
    "        # Load image\n",
    "        img_path = os.path.join(image_dir, image_file)\n",
    "        img = cv2.imread(img_path)\n",
    "        # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for matplotlib\n",
    "\n",
    "        # Load corresponding label file\n",
    "        label_file = image_file.replace('.jpg', '.txt').replace('.png', '.txt')\n",
    "        label_path = os.path.join(label_dir, label_file)\n",
    "        \n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                for line in f.readlines():\n",
    "                    # Each line in label file: class_idx x_center y_center width height (normalized)\n",
    "                    class_idx, x_center, y_center, width, height = map(float, line.strip().split())\n",
    "                    class_idx = int(class_idx)\n",
    "\n",
    "                    # Convert normalized coordinates to pixel values\n",
    "                    h, w, _ = img.shape\n",
    "                    x_center *= w\n",
    "                    y_center *= h\n",
    "                    width *= w\n",
    "                    height *= h\n",
    "                    x1 = x_center - width / 2\n",
    "                    y1 = y_center - height / 2\n",
    "                    x2 = x_center + width / 2\n",
    "                    y2 = y_center + height / 2\n",
    "\n",
    "                    # Draw the bounding box with the corresponding color\n",
    "                    plot_one_box([x1, y1, x2, y2], img, color=colors[class_idx], label=class_names[class_idx])\n",
    "\n",
    "        # Plot the image in the corresponding subplot\n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].axis('off')  # Turn off axis labels\n",
    "\n",
    "    # Reduce white space between plots\n",
    "    plt.subplots_adjust(wspace=0.02, hspace=0.02)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 16 training images\n",
    "visualize_ground_truth(train_images_path, train_labels_path, class_names, num_images=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clone YOLOv5 repository and start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The original framework can be cloned before its customization\n",
    "if not os.path.exists('yolov5'):\n",
    "    !git clone https://github.com/ultralytics/yolov5.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the notebook name manually\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"Training/yolo5.ipynb\"\n",
    "\n",
    "# Initialize Weights & Biases (W&B) project with hyperparameter configurations\n",
    "wandb.init(project=\"YOLOv5-experiments\", name=\"Run\", config={\n",
    "    \"model\": \"yolov5l\",    \n",
    "    \"epochs\": EPOCHS,     \n",
    "    \"batch_size\": 8,      \n",
    "    \"img_size\": 320\n",
    "})\n",
    "\n",
    "# Log the configuration for easy reference\n",
    "config = wandb.config\n",
    "\n",
    "if TRAIN:\n",
    "    # Train the YOLOv5 model and log metrics to W&B, using custom hyperparameters\n",
    "    !python3 yolov5/train.py --data ./data.yaml --cfg {config.model}.yaml --weights yolov5/yolov5l.pt \\\n",
    "    --img {config.img_size} --epochs {config.epochs} --batch-size {config.batch_size} \\\n",
    "    --name Run --project YOLOv5-experiments --entity greta-leonaviciene-dg \\\n",
    "    --hyp custom_hyp.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the last training run results (using file index)\n",
    "def show_last_valid_results(res_dir):\n",
    "    # Find the directory with the highest Run number\n",
    "    highest_run_id = -1\n",
    "    run_path = None\n",
    "    for folder_name in os.listdir(res_dir):\n",
    "        folder_path = os.path.join(res_dir, folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            folder_ids = folder_name.split('Run')\n",
    "            \n",
    "            # Special case, when there is a single directory\n",
    "            if \"Run\" in folder_name and len(folder_ids) == 2 and len(folder_ids[1]) == 0:\n",
    "                run_id = 0\n",
    "                if run_id > highest_run_id:\n",
    "                    highest_run_id = run_id\n",
    "                    run_path = os.path.join(res_dir, \"Run\")\n",
    "\n",
    "            # Typically directories have an index after \"Run\"\n",
    "            if \"Run\" in folder_name and len(folder_ids) == 2 and len(folder_ids[1]) > 0:\n",
    "                try:\n",
    "                    run_id = int(folder_ids[1])\n",
    "                    if run_id > highest_run_id:\n",
    "                        highest_run_id = run_id\n",
    "                        run_path = os.path.join(res_dir, f\"Run{run_id}\")\n",
    "\n",
    "                except Exception as ex:\n",
    "                    print(\"Could not parse folder id: \", str(ex))\n",
    "    \n",
    "    # Escape, if folder could not be found\n",
    "    if highest_run_id == -1:\n",
    "        print(\"Run directory could not be found\")\n",
    "        return\n",
    "    \n",
    "    validation_pred_images = glob.glob(f\"{run_path}/*_pred.jpg\")\n",
    "    print(f\"Loading directory: {run_path}\\n\", \"images: \", validation_pred_images)\n",
    "    for pred_image in validation_pred_images:\n",
    "        image = cv2.imread(pred_image)\n",
    "        plt.figure(figsize=(19, 16))\n",
    "        plt.imshow(image[:, :, ::-1])\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"YOLOv5-experiments\"\n",
    "show_last_valid_results(results_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
